{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3159d494-6694-4246-aa08-e2405f5053bb",
   "metadata": {},
   "source": [
    "# PySpark RDD Tutorial \n",
    "\n",
    "RDD (Resilient Distributed Dataset) is a fundamental building block of PySpark which is fault-tolerant, immutable distributed collections of objects.\n",
    "Immutable meaning once you create an RDD you cannot change it. Each record in RDD is divided into logical partitions, which can be computed\n",
    "on different nodes of the cluster.\n",
    "\n",
    "In other words, RDDs are a collection of objects similar to list in Python, with the difference being RDD is computed on several processes scattered \n",
    "across multiple physical servers also called nodes in a cluster while a Python collection lives and process in just one process.\n",
    "\n",
    "Additionally, RDDs provide data abstraction of partitioning and distribution of the data designed to run computations in parallel on several nodes,\n",
    "while doing transformations on RDD we don't have to worry about the parallelism as PySpark by default provides.\n",
    "\n",
    "This PySpark RDD tutorial describes the basic operations available on RDDs, such as `map()` , `filter()` , and `persist()` and many more. In addition, \n",
    "this tutorial also explains Pair RDD functions that operate on RDDs of key-value pairs such as `groupByKey()` and `join()` etc.\n",
    "\n",
    "Note: RDDs can have a name and unique idenitifie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
