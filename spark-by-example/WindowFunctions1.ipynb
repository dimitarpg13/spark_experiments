{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "850a700f-11d4-4d01-93b5-fcddd2a4336d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the below table defines Ranking and Analytics functions and for aggregate functions, we can\n",
    "# use any existing aggregate functions as a window function.\n",
    "#\n",
    "# To perform an operation on a group first, we need to partition the data using `Window.partitionBy()` \n",
    "# and for row number and rank function we need to additionally order by on partition data using \n",
    "# `orderBy` clause.\n",
    "#\n",
    "# Window Function Syntax       PySpark Window Function Description\n",
    "#\n",
    "# row_number(): Column         Returns a sequential number starting from 1 within a window partition\n",
    "#\n",
    "# rank(): Column               Returns the rank of rows within a window partition, with gaps\n",
    "#\n",
    "# percent_rank(): Column       Returns the percentile rank of rows within a window partition\n",
    "#\n",
    "# dense_rank(): Column         Returns the rank of rows within a window partition without any gaps.\n",
    "#                              Where as rank() rturns rank with gap.\n",
    "# ntile(n: Int): Column        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e1b491e-1c8a-4bab-8cfa-475080522d37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "461b65f2-c181-4bf7-a123-36cf7322a6f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a0e9d90-5b7c-4ff6-9b65-762ce824cb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "simpleData = ((\"James\", \"Sales\", 3000), \\\n",
    "              (\"Michael\", \"Sales\", 4600),  \\\n",
    "              (\"Robert\", \"Sales\", 4100),   \\\n",
    "              (\"Maria\", \"Finance\", 3000),  \\\n",
    "              (\"James\", \"Sales\", 3000),    \\\n",
    "              (\"Scott\", \"Finance\", 3300),  \\\n",
    "              (\"Jen\", \"Finance\", 3900),    \\\n",
    "              (\"Jeff\", \"Marketing\", 3000), \\\n",
    "              (\"Kumar\", \"Marketing\", 2000),\\\n",
    "              (\"Saif\", \"Sales\", 4100) \\\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30795a15-8672-43d6-ac19-98be461807c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columns= [\"employee_name\", \"department\", \"salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12750f7-d930-4e39-ac55-7cae6eafaf9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data = simpleData, schema = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e694d9-12d9-46ff-8664-80317cba7338",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e65e03c8-431c-4956-ab3b-731e86b8f45f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|James        |Sales     |3000  |\n",
      "|Michael      |Sales     |4600  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Scott        |Finance   |3300  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|Saif         |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c86aaad5-b2c7-44b2-91b7-bf959f4a4c67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3258cb9-f2ca-4dc5-88b4-f48fbd2dfcf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import row_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e84bbe6-ab59-44bd-85c1-290d554a6610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(\"department\").orderBy(\"salary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71c6518c-129a-414b-87e9-6175c439c016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----------+\n",
      "|employee_name|department|salary|row_number|\n",
      "+-------------+----------+------+----------+\n",
      "|Maria        |Finance   |3000  |1         |\n",
      "|Scott        |Finance   |3300  |2         |\n",
      "|Jen          |Finance   |3900  |3         |\n",
      "|Kumar        |Marketing |2000  |1         |\n",
      "|Jeff         |Marketing |3000  |2         |\n",
      "|James        |Sales     |3000  |1         |\n",
      "|James        |Sales     |3000  |2         |\n",
      "|Robert       |Sales     |4100  |3         |\n",
      "|Saif         |Sales     |4100  |4         |\n",
      "|Michael      |Sales     |4600  |5         |\n",
      "+-------------+----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"row_number\", row_number().over(windowSpec)) \\\n",
    "                                        .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1d0cf11-f0c6-4027-a225-770f14937c7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# rank function\n",
    "from pyspark.sql.functions import rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed33106a-918c-43bc-9c44-fd99933b1f40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----+\n",
      "|employee_name|department|salary|rank|\n",
      "+-------------+----------+------+----+\n",
      "|        Maria|   Finance|  3000|   1|\n",
      "|        Scott|   Finance|  3300|   2|\n",
      "|          Jen|   Finance|  3900|   3|\n",
      "|        Kumar| Marketing|  2000|   1|\n",
      "|         Jeff| Marketing|  3000|   2|\n",
      "|        James|     Sales|  3000|   1|\n",
      "|        James|     Sales|  3000|   1|\n",
      "|       Robert|     Sales|  4100|   3|\n",
      "|         Saif|     Sales|  4100|   3|\n",
      "|      Michael|     Sales|  4600|   5|\n",
      "+-------------+----------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"rank\",rank().over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b156e126-f9af-4a54-b38d-3ea44090d86b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+----------+\n",
      "|employee_name|department|salary|dense_rank|\n",
      "+-------------+----------+------+----------+\n",
      "|        Maria|   Finance|  3000|         1|\n",
      "|        Scott|   Finance|  3300|         2|\n",
      "|          Jen|   Finance|  3900|         3|\n",
      "|        Kumar| Marketing|  2000|         1|\n",
      "|         Jeff| Marketing|  3000|         2|\n",
      "|        James|     Sales|  3000|         1|\n",
      "|        James|     Sales|  3000|         1|\n",
      "|       Robert|     Sales|  4100|         2|\n",
      "|         Saif|     Sales|  4100|         2|\n",
      "|      Michael|     Sales|  4600|         3|\n",
      "+-------------+----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dense_rank window function is used to get the result with rank of rows within a window partition without any gaps. \n",
    "# this is similar to rank function with difference being rank function leaves gaps in rank when there are ties.\n",
    "from pyspark.sql.functions import dense_rank\n",
    "df.withColumn(\"dense_rank\", dense_rank().over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6f0b738-cc42-4a92-a077-b6c4ac3495c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+------------+\n",
      "|employee_name|department|salary|percent_rank|\n",
      "+-------------+----------+------+------------+\n",
      "|        Maria|   Finance|  3000|         0.0|\n",
      "|        Scott|   Finance|  3300|         0.5|\n",
      "|          Jen|   Finance|  3900|         1.0|\n",
      "|        Kumar| Marketing|  2000|         0.0|\n",
      "|         Jeff| Marketing|  3000|         1.0|\n",
      "|        James|     Sales|  3000|         0.0|\n",
      "|        James|     Sales|  3000|         0.0|\n",
      "|       Robert|     Sales|  4100|         0.5|\n",
      "|         Saif|     Sales|  4100|         0.5|\n",
      "|      Michael|     Sales|  4600|         1.0|\n",
      "+-------------+----------+------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# percent_rank Window Function\n",
    "\n",
    "from pyspark.sql.functions import percent_rank\n",
    "df.withColumn(\"percent_rank\", percent_rank().over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12645d7a-a57c-4274-83fe-68cefe282044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ntile window function returns the relative rank of result rows within a window partition.\n",
    "# In below example we have used 2 as an argument to ntile hence it returns ranking beteen 2 values (1 and 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cded152-14e3-4fce-a58d-a4c5892482bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+-----+\n",
      "|employee_name|department|salary|ntile|\n",
      "+-------------+----------+------+-----+\n",
      "|        Maria|   Finance|  3000|    1|\n",
      "|        Scott|   Finance|  3300|    1|\n",
      "|          Jen|   Finance|  3900|    2|\n",
      "|        Kumar| Marketing|  2000|    1|\n",
      "|         Jeff| Marketing|  3000|    2|\n",
      "|        James|     Sales|  3000|    1|\n",
      "|        James|     Sales|  3000|    1|\n",
      "|       Robert|     Sales|  4100|    1|\n",
      "|         Saif|     Sales|  4100|    2|\n",
      "|      Michael|     Sales|  4600|    2|\n",
      "+-------------+----------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"ntile\"\"\"\n",
    "from pyspark.sql.functions import ntile\n",
    "df.withColumn(\"ntile\",ntile(2).over(windowSpec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe15b50-1e90-4517-a86e-c6bc954483a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f11c0a1-8d9a-452b-a986-16c0ed7cf7aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
